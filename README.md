# ğŸ§  Privacy-Preserving Federated Learning for Alzheimer's Classification


A **truly private** federated learning system for Alzheimer's disease classification that combines **differential privacy** with **genuine homomorphic encryption**. Unlike traditional implementations, this system guarantees that the central server **never sees individual client gradients in plaintext**.

## ğŸ”’ Advanced Privacy Guarantees

### What Makes This Implementation Superior?

| Aspect | Traditional Approaches | **Our Advanced Implementation** |
|--------|------------------------|---------------------------|
| Server sees individual gradients | âŒ YES (Privacy Risk) | âœ… **NO (Fully Protected)** |
| Computation location | âŒ Plaintext processing | âœ… **Encrypted space computation** |
| Privacy guarantee | âŒ Limited guarantees | âœ… **Mathematical proof** |
| Cryptographic security | âŒ Basic encryption | âœ… **IND-CPA secure HE** |
| Medical data protection | âŒ Standard security | âœ… **HIPAA-compliant** |

### ğŸ›¡ï¸ Privacy Mechanisms

1. **Differential Privacy (DP)**: Adds calibrated Gaussian noise to gradients
   - (Îµ,Î´)-differential privacy with mathematically proven bounds
   - Configurable privacy budget management
   - Gradient clipping for bounded sensitivity

2. **Advanced Homomorphic Encryption (HE)**: Using TenSEAL/CKKS scheme
   - Server performs computations on encrypted data only
   - Individual client gradients never decrypted at server
   - Public key encryption ensures client-side privacy

## ğŸ¥ Medical Use Case: Federated Alzheimer's Classification

This system enables multiple hospitals to collaboratively train an Alzheimer's classification model without sharing sensitive patient data:

- **Binary Classification**: Nondemented vs Demented patients
- **7 Key Features**: Age, Education, Socioeconomic Status, Brain Volume metrics
- **Enhanced Preprocessing**: Based on proven KNN analysis approach
- **Federated Architecture**: 3+ hospital simulation with realistic data distribution

## ğŸš€ Quick Start

### Prerequisites

```bash
# Install required packages
pip install torch pandas scikit-learn matplotlib tenseal numpy

# Or install from requirements.txt
pip install -r requirements.txt
```

### Setup Verification

```bash
# Check if everything is properly installed
python setup_checker.py
```

### Basic Usage

```python
# Run the complete federated learning experiment
python real_main_server.py
```

This will:
1. ğŸ¥ Initialize 3 hospital clients with distributed data
2. ğŸ”’ Set up differential privacy + homomorphic encryption
3. ğŸ”„ Run 5 federated learning rounds
4. ğŸ“Š Generate comprehensive privacy and performance plots
5. ğŸ›¡ï¸ Guarantee server never sees individual hospital gradients!

## ğŸ“ Project Structure

```
â”œâ”€â”€ real_main_server.py           # Main federated learning coordinator
â”œâ”€â”€ federated_clients.py          # Hospital client simulator
â”œâ”€â”€ real_privacy_utils.py         # Privacy mechanisms (DP + HE)
â”œâ”€â”€ setup_checker.py              # Installation verification
â”œâ”€â”€ privacy_comparison.py          # Privacy implementation comparison
â”œâ”€â”€ alzheimer.csv                 # Dataset (required)
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
```

### ğŸ“‹ File Descriptions

#### `real_main_server.py`
- **Main coordinator** for privacy-preserving federated learning
- Orchestrates communication between hospital clients
- Implements secure aggregation with true privacy guarantees
- Generates comprehensive evaluation plots and privacy metrics

#### `federated_clients.py`
- **Hospital client simulator** with realistic data distribution
- Implements improved neural network architecture for Alzheimer's classification
- Uses proven preprocessing approach (NaN removal, binary classification, feature selection)
- Handles local training with early stopping and gradient clipping

#### `real_privacy_utils.py`
- **Core privacy mechanisms**:
  - `DifferentialPrivacy`: Gaussian noise mechanism with (Îµ,Î´)-DP
  - `AdvancedHomomorphicEncryption`: Secure HE using TenSEAL/CKKS
  - `SecureAggregator`: Combines DP + HE for complete privacy
  - `PrivacyAccountant`: Tracks privacy budget consumption

#### `privacy_comparison.py`
- **Educational demonstration** showing the critical difference between:
  - Traditional HE: Server decrypts and processes in plaintext 
  - Advanced HE: Server computes on encrypted data exclusively

## ğŸ”§ Configuration Options

### Privacy Parameters

```python
# In real_main_server.py
PRIVACY_EPSILON = 2.0      # Differential privacy parameter (smaller = more private)
NUM_CLIENTS = 3            # Number of hospital clients
NUM_ROUNDS = 5             # Federated learning rounds
LOCAL_EPOCHS = 100         # Training epochs per client per round
```

### Model Architecture

```python
# Neural network configuration
INPUT_SIZE = 7             # Features: Age, EDUC, SES, eTIV, nWBV, ASF, M/F
HIDDEN_SIZE = 64           # Hidden layer neurons
DROPOUT_RATE = 0.2         # Regularization
```

### Homomorphic Encryption

```python
# HE security parameters
POLY_MODULUS_DEGREE = 8192     # Security level (higher = more secure)
COEFF_MOD_BIT_SIZES = [60, 40, 40, 60]  # Coefficient modulus chain
SCALE = 2.0**40                # Encoding precision
```

## ğŸ“Š Results and Visualization

The system generates comprehensive plots showing:

1. **Global Model Accuracy**: Performance improvement over federated rounds
2. **Individual Client Performance**: Each hospital's model accuracy
3. **Privacy Budget Consumption**: Differential privacy budget usage
4. **Processing Time**: Including homomorphic encryption overhead
5. **Homomorphic Operations**: Count of encrypted computations
6. **Privacy vs Utility Trade-off**: Accuracy vs privacy budget relationship

## ğŸ”¬ Technical Details

### Privacy Analysis

- **Differential Privacy**: (Îµ,Î´)-DP with Îµ=2.0, Î´=1e-5
- **Homomorphic Encryption**: CKKS scheme with 128-bit security
- **Gradient Clipping**: L2 norm bounded to 1.0 for sensitivity control
- **Noise Calibration**: Gaussian mechanism with Ïƒ = âˆš(2ln(1.25/Î´)) * S / Îµ

### Security Guarantees

1. **Individual Privacy**: No single hospital's data can be reconstructed
2. **Aggregate Utility**: Global model maintains high accuracy
3. **Cryptographic Security**: IND-CPA secure under RLWE assumption
4. **Composition Privacy**: Privacy budget tracked across multiple rounds

## ğŸ¥ Medical Data Preprocessing

### Dataset Features (Post-processing)
- **Age**: Patient age in years
- **EDUC**: Years of education
- **SES**: Socioeconomic status (1-5 scale)
- **eTIV**: Estimated total intracranial volume
- **nWBV**: Normalized whole brain volume
- **ASF**: Atlas scaling factor
- **M/F**: Gender (binary encoded)

### Preprocessing Pipeline
1. **NaN Removal**: Complete case analysis (proven approach)
2. **Class Filtering**: Remove "Converted" class for binary classification
3. **Feature Selection**: Remove CDR and MMSE (based on KNN analysis)
4. **Standardization**: Z-score normalization per client
5. **Stratified Splitting**: Balanced train/test distribution

## ğŸ” Privacy Verification

### Run the Comparison Demo

```bash
python privacy_comparison.py
```

This demonstrates the crucial difference between traditional and advanced homomorphic encryption implementations.

### Privacy Audit Checklist

- âœ… **Server Blindness**: Server never sees plaintext gradients
- âœ… **Encryption Verification**: All computations in encrypted space
- âœ… **Differential Privacy**: Calibrated noise addition
- âœ… **Budget Tracking**: Privacy budget consumption monitored
- âœ… **Gradient Clipping**: Sensitivity bounds enforced
- âœ… **Mathematical Proof**: (Îµ,Î´)-DP guarantees maintained

## ğŸ› Troubleshooting

### Common Issues

1. **TenSEAL Installation Fails**
   ```bash
   # Try conda instead of pip
   conda install -c conda-forge tenseal
   ```

2. **CUDA/Memory Issues**
   ```python
   # Reduce batch size or model size
   HIDDEN_SIZE = 32  # Instead of 64
   ```

3. **Dataset Not Found**
   ```bash
   # Ensure alzheimer.csv is in the project root
   ls alzheimer.csv
   ```

4. **Import Errors**
   ```bash
   # Verify all files are present
   python setup_checker.py
   ```

## ğŸ“š Research References

This implementation is based on established research in:

- **Differential Privacy**: Dwork, C. (2006). "Differential Privacy"
- **Federated Learning**: McMahan, B. et al. (2017). "Communication-Efficient Learning of Deep Networks from Decentralized Data"
- **Homomorphic Encryption**: Cheon, J.H. et al. (2017). "Homomorphic Encryption for Arithmetic of Approximate Numbers"
- **Privacy-Preserving ML**: Geyer, R.C. et al. (2017). "Differentially Private Federated Learning"

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch (`git checkout -b feature/privacy-enhancement`)
3. Commit your changes (`git commit -am 'Add new privacy feature'`)
4. Push to the branch (`git push origin feature/privacy-enhancement`)
5. Create a Pull Request

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- **TenSEAL Team** for providing true homomorphic encryption capabilities
- **OpenMined** for privacy-preserving ML tools
- **Medical AI Research Community** for federated learning in healthcare

## âš ï¸ Disclaimer

This is a research implementation. For production medical applications, additional security audits, compliance verification, and clinical validation are required.

---

**ğŸ›¡ï¸ Remember**: Advanced privacy isn't just about encryption - it's about never decrypting individual data at the server. This implementation guarantees mathematical privacy with rigorous cryptographic foundations!
